\phantomsection
\chapter[\textit{E.~coli}’s Genius Exploration Algorithm]{\textit{E.~coli}’s Genius Exploration Algorithm\chapsubhead{with Shuanger Li}}
\label{chapter:chemotaxis}
\renewcommand{\chaptertitle}{E.~Coli's Genius Exploration Algorithm}
\addcontentsline{cc}{chapter}{Chapter \thechapter} % Adds chapter number to table of contents

\FloatBarrier

\section{Introduction: The Lost Immortals}
\label{sec:introduction}
\phantomsection

The book \textit{What If?}, by Randall Munroe, compiles a collection of crazy scientific hypotheticals, paired with thorough discussions of what might happen if these situations occurred. One such hypothetical, called ``Lost Immortals'', ponders how two immortal humans might find each other if they were stranded in different locations of an uninhabited planet.

We could imagine many ideas for how the immortals could reunite. For example, they could avoid the interiors of continents by moving to the coastlines. If they are allowed to discuss how to find each other in advance, then they could agree to meet at the planet's North Pole --- assuming that the planet lacks polar bears.

But Munroe provides a solution that is both sophisticated and elegant. He argues that without additional information, the immortals should walk randomly, leaving markers in their wake pointing in the direction that they travel, and resting frequently. If one immortal finds the other's trail, then they should follow it, resting less and traveling faster, until some time has expired or they lose the trail.

In the previous two chapters, we have harnessed the power of randomness to answer practical questions. Munroe's approach exemplifies a \textdef{randomized algorithm}{random algorithm}{a method that uses randomness to solve a problem}, or a method that uses randomness to solve a problem. In fact, this algorithm is inspired by nature; Munroe calls the approach ``be an ant'' because it mimics how ants explore their environment for resources. In this chapter, we will see that the Lost Immortals algorithm is also similar to the method of exploration taken by a much smaller organism: our old friend \textit{E. coli}.

Like other prokaryotes, \textit{E. coli} is tiny, with a rod-shaped body that is 2 µm long and 0.25 to 1 µm wide. In exploring a vast world with sparse resources, \textit{E. coli} finds itself in a situation comparable to the Munroe's immortals.

The movement of organisms like \textit{E. coli} in response to a chemical stimulus is called \textdef{chemotaxis}{chemotaxis}{the movement of an organism in response to a chemical stimulus}. \textit{E. coli} and other bacteria have evolved to move toward \textdefnogloss{attractants} like glucose and electron acceptors and move away from \textdefnogloss{repellents} like Ni\textsuperscript{2+} and Co\textsuperscript{2+}.

In this chapter, we will delve into chemotaxis and ask a number of questions. How does a simple organism like \textit{E. coli} sense an attractant or repellent in its environment? How does the bacterium change its internal state accordingly? How can we model the bacterium's response? And how does the bacterium's behavior translate into an ``algorithm'' that it uses to explore its environment?\\

\FloatBarrier
\phantomsection
\section{\textit{E. coli} Explores Its World Via a Random Walk}
\label{sec:e_coli_explores_its_world_via_a_random_walk}

\phantomsection
\subsection{Bacterial runs and tumbles}

Every \textit{E. coli} cell has between five and twelve flagella distributed on its surface that can rotate both clockwise and counter-clockwise. When all of the flagella are rotating counter-clockwise, they form a bundle and propel the cell forward at about 20 µm per second. This speed may seem insignificant, but it is about ten times the length of the cell per second, which is analogous to a car traveling at 160 kph. When a flagellum rotates clockwise, the flagella become uncoordinated, and the bacterium stops and rotates.

When we examine the bacterium's movement under a microscope, we see it alternate between periods of ``running'' in a straight line and then ``tumbling'' in place (\autoref{fig:chemotaxis_intro_runtumble}). Over time, the bacterium's \textdef{run and tumble}{run and tumble model}{an alternation between traveling in a straight line and rotating in place, which models bacteria exploring their environment} exploration amounts to a \textit{random walk} through its environment, like the exploration approach used by the lost immortals.\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.6\textwidth]{../images/chemotaxis_intro_runtumble.png}
\caption{The run and tumble mechanism of bacterial movement produces a random walk (bottom left).}
\label{fig:chemotaxis_intro_runtumble}
\end{figure}

\begin{qbox}[%
Say that a bacterium travels 20 µm per second, and every second it chooses a random direction in which to travel.  After an hour, approximately how far do we expect it to be from its starting point?? (Hint: recall the Random Walk Theorem from \autoref{chapter:turing}.)
]\end{qbox}

\FloatBarrier
\phantomsection
\subsection{Tumbling frequency is constant across species}

Bacteria are amazingly diverse. They have evolved for over three billion years to thrive in practically every environment on the planet, including hazardous human-made environments. They manufacture compounds such as antibiotics that larger organisms like ourselves cannot make. Some eukaryotes are even completely dependent upon bacteria to perform some critical task for them, from digesting their food, to camouflaging them from predators, to helping them develop organs.

And yet despite the diversity of the bacterial kingdom, variations in bacterial tumbling frequencies are relatively small. In the absence of an attractant or repellent, \textit{E. coli} stops to tumble once every 1 to 1.5 seconds, which is similar to most other bacteria.

It is as if some invisible force compels all these bacteria to tumble with the same frequency. Recalling Dobzhansky's quotation from \autoref{chapter:motifs} that ``nothing in biology makes sense except in the light of evolution'', we wonder why evolution might hold tumbling frequency constant across species.

This question is a fundamental one, and we will return to it at the close of this chapter after we have learned more about the biochemical basis of chemotaxis and how a bacterium can adjust its behavior in response to a chemical substance. In the process, we will see that despite bacteria being simple organisms, the mechanism that they use to implement chemotaxis is sophisticated and beautiful.\\


\FloatBarrier
\phantomsection
\section{Signaling and Ligand-Receptor Dynamics}
\label{sec:signal}

\phantomsection
\subsection{Cells detect and transduce signals via receptor proteins}

Chemotaxis is one of many ways in which a cell must perceive a change in its environment and react accordingly. This response is governed by a process called \textdef{signal transduction}{signal transduction}{the intracellular transmission of an external stimulus in order to effect a response}, in which a cell identifies a stimulus outside the cell and then transmits this stimulus into the cell in order to effect a response. When a certain molecule's extracellular concentration increases, \textdef{receptor proteins}{receptor protein}{a protein on the surface of the cell that binds to molecules in order to detect changes in their extracellular concentration} on the outside of the cell have more frequent binding with these molecules and are therefore able to detect changes in molecular concentration. This ``signal is then ``transduced'' via a series of internal chemical processes.

For example, transcription factors are involved in a signal transduction process that we illustrated in \autoref{fig:transduction}. When some extracellular molecule is detected, a cascade begins that eventually changes a transcription factor into an active state, so that it is ready to activate or repress the genes that it regulates.

In the case of chemotaxis, \textit{E. coli} has receptor proteins that detect attractants such as glucose by binding to and forming a complex with these attractant \textdef{ligands}{ligand}{a substance that forms a complex with a biological molecule such as a receptor protein}. The bacterium also contains receptors to detect repellents, but we will focus on modeling the binding of a single type of receptor to a single type of attractant ligand. Soon, we will enter the cell and model the cascade of reactions occurring after this complex has formed that will cause a change in the rotation of one or more flagella (\autoref{fig:chemotaxis_signal}).\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_signal.png}
\caption{An overview of the chemotaxis signaling pathway. The red circles labeled \textit{L} represent attractant ligands. When these ligands bind to receptors, a signal is transduced inside the cell via a series of enzymes, which eventually influences the rotation direction of a flagellum.}
\label{fig:chemotaxis_signal}
\end{figure}

\FloatBarrier
\nopagebreak
\phantomsection
\subsection{Ligand-receptor dynamics can be modeled by a reversible reaction}

The chemical reactions that we have considered earlier in this book are \textdef{irreversible}{irreversible reaction}{a chemical reaction that only proceeds in one direction}, meaning they can only proceed in one direction. For example, in \autoref{chapter:turing}'s reaction-diffusion model, we modeled the reaction $A + 2B \rightarrow 3B$, but we did not consider the reverse reaction $3B \rightarrow A + 2B$.

To model ligand-receptor dynamics, we will use a \textdef{reversible reaction}{reversible reaction}{a chemical reaction that proceeds continuously in both directions (at possibly different rates)} that proceeds continuously in both directions at possibly different rates. If a ligand collides with a receptor, then there is some probability that the two molecules will bind into a complex. At the same time, in any unit of time, there is also some probability that a bound receptor-ligand complex will \textdefnogloss{dissociate} into two separate molecules. In \autoref{chapter:coronavirus_2}, we will discuss some of the biochemical details underlying what makes two molecules more or less likely to bind, but for now, we assert that the more suited a receptor is to a ligand, the higher the binding rate and the lower the dissociation rate.\\

\begin{note}[%
You may be wondering why ligand-receptor binding is reversible. If complexes did not dissociate, then a brief increase in ligand concentration would be detected indefinitely by the surface receptors. Without releasing the bound ligands, the cell would need to manufacture more and more receptors, which are complicated molecules.
]\end{note}

We denote the ligand molecule by $L$, the receptor molecule by $T$, and the bound complex as $LT$. The reversible reaction representing complex binding and dissociation is $L + T \longleftrightarrow LT$ and consists of two reactions. The \textdefnogloss{forward reaction} is $L + T \rightarrow LT$, which occurs at a rate depending on some rate constant $k_\text{bind}$, and the \textdefnogloss{reverse reaction} is $LT \rightarrow L + T$, which occurs at a rate depending on some rate constant $k_\text{dissociate}$.

If we start with a free floating supply of $L$ and $T$ molecules, then $LT$ complexes will initially be formed quickly at the expense of the free-floating $L$ and $T$ molecules. The reverse reaction will not occur because of the lack of $LT$ complexes. However, as the concentration of $LT$ grows and the concentrations of $L$ and $T$ decrease, the rate of increase in the concentration of $LT$ will slow. Eventually, the number of $T$ complexes being formed by the forward reaction will balance the number of $LT$ complexes being split apart by the reverse reaction. At this point, the concentration of all particles reaches equilibrium.

\FloatBarrier
\phantomsection
\subsection{Calculation of equilibrium in a reversible ligand-receptor reaction}

For a single reversible reaction, if we know the rates of both the forward and reverse reactions, then we can calculate the steady state concentrations of $L$, $T$, and $LT$ by hand.  Suppose that we begin with initial concentrations of $L$ and $T$ that are represented by $l_0$ and $t_0$, respectively. Let $[L]$, $[T]$, and $[LT]$ denote the concentrations of the three molecule types. And assume that the reaction rate constants $k_\text{bind}$ and $k_\text{dissociate}$ are fixed.

When the steady state concentration of $LT$ is reached, the rates of the forward and reverse reactions are equal. In other words, the number of complexes being produced is equal to the number of complexes dissociating:

\begin{center}
$k_\text{bind} \cdot [L] \cdot [T] = k_\text{dissociate} \cdot [LT] $\,.

\end{center}

We also know that by the law of conservation of mass, the concentrations of $L$ and $T$ molecules are always constant across the system and are equal to their initial concentrations. That is, at any time point,
\begin{align*}
[L] + [LT] & = l_0\,;\\
[T] + [LT] & = t_0\,.
\end{align*}

\noindent We solve these two equations for $[L]$ and $[T]$ to yield
\begin{align*}
[L] & = l_0 - [LT]\,;\\
[T] & = t_0 - [LT]\,.
\end{align*}

\noindent We substitute the expressions on the right for $[L]$ and $[T]$ into our original steady state equation:

\begin{center}
$k_\text{bind} \cdot (l_0 - [LT]) \cdot (t_0 - [LT]) = k_\text{dissociate} \cdot [LT]$\,.
\end{center}

\noindent We then expand of the left side of the above equation:

\begin{center}
$k_\text{bind} \cdot [LT]^2 - (k_\text{bind} \cdot l_0 + k_\text{bind} \cdot t_0) \cdot [LT]  = k_\text{dissociate} [LT] + k_\text{bind} \cdot l_0 \cdot t_0$\,.
\end{center}

\noindent Finally, we subtract the right side of this equation from both sides to give

\begin{center}
$k_\text{bind} \cdot [LT]^2 - (k_\text{bind} \cdot l_0 + k_\text{bind} \cdot t_0 + k_\text{dissociate}) \cdot [LT] + k_\text{bind} \cdot l_0 \cdot t_0 = 0$\,.
\end{center}

\noindent This equation may look daunting, but most of its components are constants. In fact, the only unknown is $[LT]$, which makes this a quadratic equation, with $[LT]$ as the variable.

In general, a quadratic equation has the form $a \cdot x^2 + b \cdot x + c = 0$ for a single variable $x$ and constants $a$, $b$, and $c$. In our case, $x$ = $[LT]$, $a = k_\text{bind}$, $b = - (k_\text{bind} \cdot l_0 + k_\text{bind} \cdot t_0 + k_\text{dissociate})$, and $c = k_\text{bind} \cdot l_0 \cdot t_0$. The quadratic formula --- which you may have thought you would never use again --- tells us that the quadratic equation has solutions for $x$ given by

\begin{center}
$x = \dfrac{-b \pm \sqrt{b^2 - 4 \cdot a \cdot c}}{2 \cdot a}$\,.
\end{center}

\fudgespace

\begin{qbox}[%
Use the quadratic formula to find the steady state concentration of $LT$. How can we use this solution to find the steady state concentrations of $L$ and $T$ as well?
]\end{qbox}

Now that we have reduced the computation of the steady state concentration of $LT$ to the solution of a quadratic equation, we will compute this steady state concentration for a sample collection of parameters. Say that we are given the following parameter values (the units of these parameters are not important for this toy example):
\begin{align*}
k_\text{bind} & = 2\,;\\
k_\text{dissociate} & = 5\,;\\
l_0 & = 50\,;\\
t_0 & = 50\,.
\end{align*}

%\begin{itemize}
% \item $k_\text{bind}= 2$;
% \item $k_\text{dissociate} = 5$;
% \item $l_0 = 50$;
% \item $t_0 = 50$.
%\end{itemize}

\noindent Substituting these values into the quadratic equation, we obtain
\begin{align*}
a & = k_\text{bind} = 2\,;\\
b & = - (k_\text{bind} \cdot l_0 + k_\text{bind} \cdot t_0 + k_\text{dissociate}) = -205\,;\\
c & = k_\text{bind} \cdot l_0 \cdot t_0 = \text{5,000}\,.
\end{align*}

\noindent That is, we are solving the equation $2 \cdot [LT]^2 - 205 \cdot [LT] + 5000 = 0$. Using the quadratic formula to solve for $[LT]$ gives

\begin{center}
$[LT] = \dfrac{205 \pm \sqrt{205^2 - 4 \cdot 2 \cdot 5000}}{2 \cdot 2} = 51.25 \pm 11.25$\,.
\end{center}

It would seem that this equation has \textit{two} solutions: $[LT] = 51.25 + 11.25 = 62.5$ and $[LT] = 51.25 - 11.25 = 40$. Yet because $l_0$ and $t_0$, the respective initial concentrations of $L$ and $T$, are both equal to 50, the first ``solution'' would imply that $[L] = l_0 - [LT] = 50 - 62.5 = -12.5$ and $[T] = t_0 - [LT] = 50 - 62.5 = -12.5$, which is impossible because the concentration of a particle cannot be negative. 

Now that we know the steady state concentration of $LT$ must be 40, we can recover the values of $[L]$ and $[T]$ as
\begin{align*}
[L] & = l_0 - [LT] = 10\,;\\
[T] & = t_0 - [LT] = 10\,.
\end{align*}

What if the forward reaction were slower (i.e., $k_\text{bind}$ were lower)? We would imagine that the equilibrium concentration of $[LT]$ should decrease. For example, if we halve $k_\text{bind}$, then we obtain the following adjusted parameter values:
\begin{align*}
a & = k_\text{bind} = 1\,;\\
b & = - (k_\text{bind} \cdot l_0 + k_\text{bind} \cdot t_0 + k_\text{dissociate}) = -105\,;\\
c & = k_\text{bind} \cdot l_0 \cdot t_0 = \text{2,500}\,.
\end{align*}

\noindent In this case, if we solve the quadratic equation for $[LT]$, then we obtain

\begin{center}
$[LT] = \dfrac{105 \pm \sqrt{105^2 - 4 \cdot 1 \cdot 2500}}{2 \cdot 1} = 52.5 \pm 16.008$\,.
\end{center}

\noindent The only feasible solution is $52.5-16.008 = 36.492$. As anticipated, the steady state concentration has decreased.\\

\begin{qbox}[%
What do you think will happen to the steady state concentration of $L$ if its initial concentration ($l_0$) increases or decreases? What if the dissociation rate ($k_\text{dissociate}$) increases or decreases?  Confirm your predictions by changing the parameters above and solving the quadratic formula for the concentration of $L$.
]\end{qbox}

\FloatBarrier
\phantomsection
\subsection{Where are the units?}

We have conspicuously not provided any units in the calculations above for the sake of simplicity, and so we will pause to explain what these units are. The concentration of a particle is measured in $\text{molecules}/\text{µm}^3$, the number of molecules per unit volume. But what about the binding and dissociation rates?

When we multiply the binding rate constant $k_\text{bind}$ by the concentrations $[L]$ and $[T]$, the resulting unit should be in $\text{molecules}/\text{µm}^3$ per second, which corresponds to the rate at which the concentration $[LT]$ of complexes is increasing. If we let \textvar{y} denote the unknown units of $k_\text{bind}$, then

\begin{center}
$y \cdot (\text{molecules}/\text{µm}^3) \cdot (\text{molecules}/\text{µm}^3) = (\text{molecules}/\text{µm}^3) \cdot \text{s}^{-1}$\,,
\end{center}

\noindent and solving for \textvar{y} gives

\begin{center}
$y = (\text{µm}^3/\text{molecule}) \cdot \text{s}^{-1}$\,.
\end{center}

\fudgespace

\begin{qbox}[%
Use a similar argument to show that the units of the dissociation rate $k_\text{dissociate}$ should be $\text{s}^{-1}$.
]\end{qbox}

\FloatBarrier
\phantomsection
\subsection{Steady state ligand-receptor concentrations for an experimentally verified example}

Having established the units in our model, we will solve our quadratic equation once more to identify steady state concentrations using experimentally verified binding and dissociation rates. The experimentally verified rate constant for the binding of receptors to glucose ligands is $k_\text{bind} = 0.0146~(\text{µm}^3/\text{molecule}) \cdot \text{s}^{-1}$, and the dissociation rate constant is $k_\text{dissociate} = 35\,\text{s}^{-1}$\,. We will model an \textit{E. coli} cell with 7,000 receptor molecules in an environment containing 10,000 ligand molecules. Using these values, we obtain the following constants $a$, $b$, and $c$ in the quadratic equation:
\begin{align*}
a & = k_\text{bind} = 0.0146\,;\\
b & = - (k_\text{bind} \cdot l_0 + k_\text{bind} \cdot t_0 + k_\text{dissociate}) = -283.2\,;\\
c & = k_\text{bind} \cdot l_0 \cdot t_0 = \text{1,022,000}\,.
\end{align*}

When we solve for $[LT]$ using the quadratic formula, we obtain $[LT]$ equal to 4,793 $\text{molecules}/\text{µm}^3$. Now that we have this value along with $l_0$ and $t_0$, we can solve for $[L]$ and $[T]$ as well:
\begin{align*}
[L] & = l_0 - [LT] = \text{5,207 molecules}/\text{µm}^3\,;\\
[T] & = t_0 - [LT] = \text{2,207 molecules}/\text{µm}^3\,.
\end{align*}

We can therefore determine the steady state concentration for a \textit{single} reversible reaction. However, if we want to model real cellular processes, we will have \textit{many} reactions for a variety of different particles. We will see that it quickly becomes infeasible to solve all of the resulting equations exactly. Instead, we need a method of simulating many reactions in parallel without incurring the significant computational overhead required to track the movements of every particle.\\

\FloatBarrier
\phantomsection

\section{Stochastic Simulation of Chemical Reactions}
\label{sec:stochastic_simulation_of_chemical_reactions}
\phantomsection
\subsection{Verifying a theoretical steady state concentration via stochastic simulation}

In \autoref{chapter:motifs}, we saw that we could avoid tracking the positions of individual particles if we assume that the particles are \textit{well-mixed}, i.e., uniformly distributed throughout their environment. We will apply this assumption in our current work as well, in part because the \textit{E. coli} cell is so small. As a proof of concept, we will see if a well-mixed simulation replicates a reversible reaction's equilibrium concentrations of particles that we found in the preceding section.

Even though we can calculate steady state concentrations manually, a particle-free simulation will be useful for two reasons. First, this simulation will give us snapshots of the concentrations of particles in the system over multiple time points and allow us to see how quickly the concentrations reach equilibrium. Second, we will soon expand our model of chemotaxis to have many particles and reactions that depend on each other, and direct mathematical analysis of the system will become impossible.\\

\begin{note}[%
The difficulty posed to precise analysis of systems with multiple chemical reactions is comparable to the famed ``$n$-body problem'' in physics. Predicting the motions of two celestial objects interacting due to gravity can be done exactly, but once we add more bodies to the system, no solution exists, and we must rely on simulation.
]\end{note}

Our particle-free model will apply an approach called \textdef{Gillespie's stochastic simulation algorithm}{Gillespie's stochastic simulation algorithm (SSA)}{an algorithm that simulates a well-mixed environment of particles by apply repeated sampling from an exponential distribution to determine time between reactions}, which is often called the \textbf{Gillespie algorithm} or just \textbf{SSA} for short. Before we explain how this algorithm works, we will take a short detour to provide some needed probabilistic context.

\FloatBarrier
\phantomsection
\subsection{The Poisson and exponential distributions}

Imagine that you own a store and have noticed that on average, $\lambda$ customers enter your store in a single hour. Let \textvar{X} denote the number of customers entering the store in the next hour; \textvar{X} is an example of a \textdef{random variable}{random variable}{a variable whose values may change based on random chance} because its value may change depending on random chance. If we assume that customers are independent actors, then \textvar{X} follows a \textdef{Poisson distribution}{Poisson distribution}{a distribution representing the probability of a number of events occurring in a fixed time interval if these events occur independently at a fixed rate}.

It can be shown that for a Poisson distribution, the probability that exactly $n$ customers arrive in the next hour is

\begin{center}
$\mathrm{Pr}(X = n) = \dfrac{\lambda^n e^{-\lambda}}{n!}$\,,
\end{center}

\noindent where $e$ is the mathematical constant known as Euler's number and is equal to 2.7182818284\ldots~Furthermore, the probability of observing exactly $n$ customers in $t$ hours, where $t$ is an arbitrary positive number, is

\begin{center}
$\dfrac{(\lambda t)^n e^{-\lambda t}}{n!}$\,.
\end{center}

We can also ask how long we will typically have to wait for the next customer to arrive. Specifically, what are the chances that this customer will arrive after $t$ hours? If we let \textvar{T} be the random variable corresponding to the wait time on the next customer, then the probability of \textvar{T} being at least $t$ is the probability of seeing zero customers in $t$ hours:
\begin{align*}
\mathrm{Pr}(T > t) &= \mathrm{Pr}(X = 0)\\
& = \dfrac{(\lambda t)^0 e^{-\lambda t}}{0!}\\
& = e^{-\lambda t}\,.
\end{align*}

In other words, the probability $\mathrm{Pr}(T > t)$ that the wait time is longer than time \textvar{t} decays exponentially as \textvar{t} increases. For this reason, the random variable \textvar{T} is said to follow an \textdef{exponential distribution}{exponential distribution}{a distribution representing the ``wait time'' between successive events in a Poisson distribution}. It can be shown that the expected value of the exponential distribution (i.e., the average amount of time we will need to wait for the next event to occur) is $1/\lambda$.\\

\begin{qbox}[%
What is the probability $\mathrm{Pr}(T < t)$?
]\end{qbox}

\FloatBarrier
\phantomsection
\subsection{The Gillespie algorithm}

We now return to explain the Gillespie algorithm for simulating multiple chemical reactions in a well-mixed environment. The engine of this algorithm runs on a single question: given a well-mixed environment of particles and a reaction involving those particles taking place at some average rate, how long should we expect to \textit{wait} before this reaction occurs somewhere in the environment?

This is the same question that we asked in the previous discussion; we have simply replaced customers entering a store with instances of a chemical reaction. The average number $\lambda$ of occurrences of the reaction in a unit time period is the rate $r$ at which the reaction occurs. Therefore, an exponential distribution with average wait time $1/r$ can be used to model the time between instances of the reaction.

Next, say that we have two reactions proceeding independently of each other and occurring at average rates $r_1$ and $r_2$. The combined average rates of the two reactions is $r_1 + r_2$, and the time required to wait for either of the two reactions is exponentially distributed, with an average wait time equal to $1/(r_1 + r_2)$.

Numerical methods allow us to generate a random number simulating the wait time of an exponential distribution. By repeatedly generating these numbers, we can obtain a series of wait times between consecutive reaction occurrences.

Once a wait time is selected, we should determine to which of the two reactions it corresponds. If the rates of the two reactions are equal, then we simply choose one of the two reactions randomly with equal probability. But if the rates of these reactions are different, then we should choose one of the reactions via a probability that is \textit{weighted} in direct proportion to the rate of the reaction; that is, the larger the rate of the reaction, the more likely that this reaction corresponds to the current event. To do so, we select the first reaction with probability $r_1/(r_1 + r_2)$ and the second reaction with probability $r_2/(r_1 + r_2)$. (Note that these two probabilities sum to 1.)

As illustrated in \autoref{fig:chemotaxis_visualizessa}, we will demonstrate the Gillespie algorithm by returning to our ongoing example, in which we are modeling the forward and reverse reactions of ligand-receptor binding and dissociation. These reactions have rates that are given by $r_\text{bind} = k_\text{bind} \cdot [L] \cdot [T]$ and $r_\text{dissociate} = k_\text{dissociate} \cdot [LT]$, respectively.

First, we choose a wait time according to an exponential distribution with mean value $1/(r_\text{bind} + r_\text{dissociate})$. The probability that the event corresponds to a binding reaction is given by

\begin{center}
$\mathrm{Pr}(L + T \rightarrow LT) = \dfrac{r_\text{bind}}{r_\text{bind} + r_\text{dissociate}}$\,,
\end{center}

\noindent and the probability that it corresponds to a dissociation reaction is

\begin{center}
$\mathrm{Pr}(LT \rightarrow L + T) = \dfrac{r_\text{dissociate}}{r_\text{bind} + r_\text{dissociate}}$\,.
\end{center}

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_visualizessa.png}
\caption{A visualization of a single reaction event used by the Gillespie algorithm for ligand-receptor binding and dissociation. Red circles represent ligands (\textvar{L}), and orange wedges represent receptors (\textvar{T}). The wait time for the next reaction is drawn from an exponential distribution with mean $\text{1}/(\textvar{r}_\text{bind} + \textvar{r}_\text{dissociate})$, where $\textvar{r}_\text{bind}$ and $\textvar{r}_\text{dissociate}$ are the rates of the binding and dissociation reactions, respectively. The probability of this event corresponding to a binding or dissociation reaction is proportional to the rate of the respective reaction.}
\label{fig:chemotaxis_visualizessa}
\end{figure}

When we generalize the Gillespie algorithm to \textvar{n} reactions occurring at rates $r_1$, $r_2$, \ldots, $r_n$, the wait time between reactions will be exponentially distributed with average $1 / (r_1 + r_2 + \cdots + r_n)$. Once we select the next reaction to occur, the likelihood that it is the \textvar{i}-th reaction is equal to

\begin{center}
$\dfrac{r_i}{r_1 + r_2 + \cdots + r_n}$\,.
\end{center}


\FloatBarrier
\phantomsection
\subsection{Does the Gillespie algorithm confirm our steady state calculations?}

Earlier in this chapter, we showed an example in which a system with 10,000 free ligand molecules and 7,000 free receptor molecules produced the following steady state concentrations using the experimentally verified binding rate of $k_\text{bind} = 0.0146 (\text{µm}^3/\text{molecule}) \cdot \text{s}^{-1}$ and dissociation rate of $k_\text{dissociate} = 35\,\text{s}^{-1}$:
\begin{align*}
[LT] & = \text{4,793 molecules}/\text{µm}^3\,;\\
[L] & = \text{5,207 molecules}/\text{µm}^3\,;\\
[T] & = \text{2,207 molecules}/\text{µm}^3\,.
\end{align*}

\autoref{fig:chemotaxis_tutorial4_ssa} demonstrates that when running the Gillespie algorithm with the same initial molecules and reaction rates, the system converges to the values shown above. Furthermore, we not only obtain the steady state concentrations, but we also observe that the system reaches steady state in a fraction of a tenth of a second.\tutorial[chemotaxis/tutorial\_lr]\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_tutorial4_ssa.png}
\caption{A concentration plot over time for ligand-receptor dynamics via a simulation employing the Gillespie algorithm. Time is shown (in seconds) on the x-axis, and concentration is shown (in $\text{molecules}/\text{µm}^\text{3}$) on the y-axis. The concentrations reach a steady state at the end of the simulation that matches the concentrations identified by hand.}
\label{fig:chemotaxis_tutorial4_ssa}
\end{figure}

This simple ligand-receptor model is just the beginning of our study of chemotaxis. In the next section, we will delve into the complex biochemical details of chemotaxis. Furthermore, we will see that the Gillespie algorithm for stochastic simulations will scale easily as our model of this system grows more complex.\\

\FloatBarrier
\phantomsection

\section{A Biochemically Accurate Model of Bacterial Chemotaxis}
\label{sec:a_biochemically_accurate_model_of_bacterial_chemotaxis}

\phantomsection
\subsection{Transducing an extracellular signal to a cell's interior}

We now turn to the question of how the cell conveys the extracellular signal it has detected via the process of signal transduction to the cell's interior and produces an action. When \textit{E. coli} senses an increase in the concentration of glucose, meaning that more ligand-receptor binding is taking place at the receptor that recognizes glucose, how does the bacterium change its behavior?

The engine of signal transduction is \textdef{phosphorylation}{phosphorylation}{a chemical reaction that attaches a phosphoryl group to an organic molecule}, a chemical reaction that attaches a phosphoryl group ($\text{PO}_3^{-}$) to an organic molecule.  Phosphoryl modifications serve as an information exchange of sorts because, as we will see, they activate or deactivate certain enzymes.

A phosphoryl group usually comes from one of two sources. First, the phosphoryl can be broken off of an \textdef{adenosine triphosphate (ATP)}{adenosine triphosphate (ATP)}{a molecule serving as the ``energy currency'' of the cell} molecule, the ``energy currency'' of the cell, producing \textdefnogloss{adenosine diphosphate (ADP)}. Second, the phosphoryl can be exchanged from a phosphorylated molecule that loses its phosphoryl group in a \textdef{dephosphorylation}{dephosphorylation}{a chemical reaction that removes a phosphoryl group from an organic molecule} reaction.

For many cellular responses, including bacterial chemotaxis, a sequence of phosphorylation and dephosphorylation events called a \textdefnogloss{phosphorylation cascade} serves to transmit information within the cell about the amount of ligand binding being detected on the cell's exterior. In this section, we discuss how this cascade of chemical reactions leads to a change in bacterial movement.

A high-level view of the transduction pathway for chemotaxis is shown in \autoref{fig:chemotaxisphosnew}. The cell membrane receptors that we have been working with are called \textdefnogloss{methyl-accepting chemotaxis proteins (MCPs)}, and they bridge the cellular membrane, binding both to ligand stimuli in the cell exterior and to other proteins on the inside of the cell. The pathway includes a number of additional proteins, which all start with the prefix ``Che'' (short for ``chemotaxis'').

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxisphosnew.png}
\caption{A summary of the chemotaxis transduction pathway. A ligand binding signal is propagated through CheA and CheY phosphorylation, which leads to a response of clockwise flagellar rotation. The blue curved arrow denotes phosphorylation, the grey curved arrow denotes dephosphorylation, and the blue dashed arrow denotes a chemical interaction. Our figure is a simplified view of \href{http://chemotaxis.biology.utah.edu/Parkinson_Lab/projects/ecolichemotaxis/ecolichemotaxis.html} illustrations.}
\label{fig:chemotaxisphosnew}
\end{figure}


On the interior of the cellular membrane, MCPs form complexes with two proteins called \textbf{CheW} and \textbf{CheA}. In the absence of MCP-ligand binding, this complex is more stable, and the CheA molecule \textdef{autophosphorylates}{autophosphorylation}{the process of a molecule adding a phosphoryl group to itself}, meaning that it adds a phosphoryl group taken from ATP to \textit{itself} --- a concept that might seem mystical if you have not already followed our discussion of autoregulation in \autoref{chapter:motifs}.

Phosphorylated CheA can pass on its phosphoryl group to a molecule called \textbf{CheY}, which interacts with the flagellum in the following way. Each flagellum has a protein complex called the \textdef{flagellar motor switch}{flagellar motor switch}{a protein complex on a flagellum that is responsible for controlling the direction of flagellar rotation} that is responsible for controlling the direction of flagellar rotation. The interaction of this protein complex with phosphorylated CheY induces a change of flagellar rotation from counter-clockwise to clockwise. As we discussed earlier in the chapter, this change in flagellar rotation causes the bacterium to tumble, which in the absence of an increase in attractant occurs every 1 to 1.5 seconds.

Yet when a ligand binds to the MCP, the MCP undergoes conformation changes, which reduce the stability of the complex with CheW and CheA. As a result, CheA is less readily able to autophosphorylate, which means that it does not phosphorylate CheY, which cannot change the flagellar rotation to clockwise, and so the bacterium is less likely to tumble.

In short, attractant ligand binding \textit{causes} more phosphorylated CheA and CheY, which means that it \textit{causes} fewer flagellar interactions and therefore less tumbling, so that the bacterium will run for a longer period of time.\\

\begin{note}[%
A critical part of this process is that if a ligand is detected, and the cell has a high concentration of CheY, then it needs to decrease the CheY concentration quickly. Otherwise, the cell will not be able to change its tumbling frequency. To this end, the cell is able to dephosphorylate CheY using an enzyme called \textdefnogloss{CheZ}.
]\end{note}


\FloatBarrier
\phantomsection
\subsection{Adding phosphorylation events to our model of chemotaxis}

We would like to use the Gillespie algorithm to simulate the reactions driving chemotaxis signal transduction and see what happens if the bacterium ``senses an attractant'', meaning that the attractant ligand's concentration increases and leads to more receptor-ligand binding.

This model will be more complicated than any we have introduced thus far. We will need to account for both bound and unbound MCP molecules, as well as phosphorylated and unphosphorylated CheA and CheY enzymes. We will also need to model phosphorylation reactions of CheA, which depend on the current concentrations of bound and unbound MCP molecules. We will at least make the simplifying assumption that the MCP receptor is permanently bound to CheA and CheW, so that we do not need to represent these molecules individually. In other words, rather than thinking about CheA autophosphorylating, we will think about the receptor that includes CheA autophosphorylating.

We will need six reactions. Two reversible reactions represent ligand-receptor binding, one for each of phosphorylated or unphosphorylated receptors. Two reactions represent MCP phosphorylation and take place at different rates based on whether the MCP is bound to a ligand (in our model, the phosphorylation rate is five times greater when the MCP is unbound). One reaction represents phosphorylation of CheY, and another reaction models dephosphorylation, which is mediated by the CheZ enzyme.

Once we have built this model, we would like to see what happens when we \textit{change} the concentrations of the ligand. Ideally, the bacterium should be able to distinguish different ligand concentrations. That is, the higher the concentration of an attractant ligand, the lower the concentration of phosphorylated CheY (and the lower the tumbling frequency of the bacterium that we are simulating). But will the model reflect this behavior?\tutorial[chemotaxis/tutorial_phos]

\FloatBarrier
\phantomsection
\subsection{Changing ligand concentrations leads to a change in internal molecular concentrations}

\autoref{fig:chemotaxis_concentrations} (top) shows the concentrations of phosphorylated CheA and CheY in a model of our system at equilibrium in the absence of ligand. As we might expect, these concentrations remain at steady state (with some healthy noise), and so the cell stays at its background tumbling frequency. The addition of 5,000 attractant ligand molecules increases the concentration of bound receptors, therefore leading to less CheA autophosphorylation, and less phosphorylated CheY (\autoref{fig:chemotaxis_concentrations} (middle)). If we instead have 100,000 initial attractant molecules, then we see an even more drastic decrease in phosphorylated CheA and CheY (\autoref{fig:chemotaxis_concentrations} (bottom)).

\begin{figure}[hp]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_tutorial5.png}\\[3ex]
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_tutorial6.png}\\[3ex]
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_tutorial7.png}
\caption{Molecular concentrations over time (in seconds) in a chemotaxis simulation for three different initial unbound attractant ligand concentrations: no attractant ligand (top), 5,000 ligand particles (middle), and 100,000 ligand particles (bottom). Note that the simulated cell's bound ligand concentration (green) achieves equilibrium very quickly in each case.}
\label{fig:chemotaxis_concentrations}
\end{figure}

This Gillespie model confirms the biological observations that an increase in attractant reduces the concentration of phosphorylated CheY. This reduction takes place remarkably quickly, with the cell attaining a new equilibrium in a fraction of a second.

And yet you may remain skeptical of our model. After all, the biochemistry powering chemotaxis may be elegant, but it is also simple, and perhaps you are not surprised that the model's particle concentrations reproduced the response of \textit{E. coli} to an attractant ligand.

What we have shown here is just part of the story. In the next section, we will see that the biochemical realities of chemotaxis are even more complicated, and for good reason --- this added complexity will allow \textit{E. coli} to react to a dynamic world with surprising sophistication.\\

\FloatBarrier
\phantomsection

\section{Methylation Helps a Bacterium Adapt to Differing Concentrations}
\label{sec:methylation}

\phantomsection
\subsection{Bacterial tumbling remains constant for different attractant concentrations}

The reality of cellular environments is that the concentration of an attractant can vary across several orders of magnitude. The cell therefore needs to detect not \textit{absolute} concentrations of an attractant but rather \textit{relative} changes.

\textit{E. coli} detects relative changes in its concentration via \textdefnogloss{adaptation} to these changes. If the concentration of attractant remains constant for a period of time, then regardless of the absolute value of the concentration, the cell returns to the same background tumbling frequency. In other words, \textit{E. coli} demonstrates \textit{robustness} to the attractant concentration in maintaining its default tumbling behavior.

However, our current model is not able to address this adaptation. If the ligand concentration increases in the model, then phosphorylated CheY will plummet and remain at a low steady state.

We will investigate the biochemical mechanism that \textit{E. coli} uses to achieve such a robust response to environments with different background concentrations. We will then expand the model we have built to replicate the bacterium's adaptive response.

\FloatBarrier
\phantomsection
\subsection{Bacteria remember past concentrations using methylation}

Recall that in the absence of an attractant, CheW and CheA readily bind to an MCP, leading to greater autophosphorylation of CheA, which in turn phosphorylates CheY. The greater the concentration of phosphorylated CheY, the more frequently the bacterium tumbles.

Signal transduction is achieved through phosphorylation, but \textit{E. coli} maintains a ``memory'' of past environmental concentrations through a chemical process called \textdef{methylation}{methylation}{a chemical reaction in which a methyl group ($-\text{CH}_3$) is added to an organic molecule}. In this reaction, a \textdefnogloss{methyl group} ($-\text{CH}_3$) is added to an organic molecule; the removal of a methyl group is called \textdef{demethylation}{demethylation}{the reversal of a methylation reaction, in which a methyl group ($-\text{CH}_3$) is removed from an organic molecule}.

Every MCP receptor contains four methylation sites, meaning that between zero and four methyl groups can be added to the receptor. On the plasma membrane, many MCPs, CheW, and CheA molecules form an array structure. Methylation reduces the negative charge on the receptors, stabilizing the array and facilitating CheA autophosphorylation. The more sites that are methylated, the higher the autophosphorylation rate of CheA, which means that CheY has a higher phosphorylation rate, and tumbling frequency increases.

Note that we now have two different ways that tumbling frequency can be elevated. First, if the concentration of an attractant is low, then CheW and CheA freely form a complex with the MCP, and the phosphorylation cascade passes phosphoryl groups to CheY, which interacts with the flagella and keeps tumbling frequency high. Second, an increase in MCP methylation can also boost CheA autophosphorylation and lead to an increased tumbling frequency.

Methylation of MCPs is achieved by an additional protein called \textbf{CheR}. When bound to MCPs, CheR methylates ligand-bound MCPs faster, and so the rate of MCP methylation by CheR is higher if the MCP is bound to a ligand. Let's consider how this fact affects a bacterium's behavior.

Say that \textit{E. coli} encounters an increase in attractant concentration. Then the lack of a phosphorylation cascade will mean less phosphorylated CheY, and so the tumbling frequency will decrease. However, if the attractant concentration levels off, then the tumbling frequency will flatten, while CheR starts methylating the MCP. Over time, the rising methylation will increase CheA autophosphorylation, bringing back the phosphorylation cascade and raising tumbling frequency back to default levels.

Just as the phosphorylation of CheY can be reversed, MCP methylation can be undone to prevent methylation from being permanent. In particular, an enzyme called \textbf{CheB}, which like CheY is phosphorylated by CheA, demethylates MCPs (as well as autodephosphorylates). The rate of an MCP's demethylation is dependent on the extent to which the MCP is methylated. In other words, the rate of MCP methylation is higher when the MCP is in a low methylation state, and the rate of demethylation is faster when the MCP is in a high methylation state.

\autoref{fig:chemotaxis_wholestory} adds CheR and CheB to provide a complete picture of the core pathways influencing chemotaxis. To model these pathways and see how our simulated bacterial system responds to different relative attractant concentrations, we will need to add quite a few molecules and reactions to our current model.\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_wholestory.png}
\caption{The chemotaxis signal-transduction pathway with methylation included. CheA phosphorylates CheB, which methylates MCPs, while CheR demethylates MCPs. Blue lines denote phosphorylation, grey lines denote dephosphorylation, green arrows denote methylation, and red arrows denote demethlyation.}
\label{fig:chemotaxis_wholestory}
\end{figure}


\FloatBarrier
\phantomsection
\subsection{Combinatorial explosion and the need for rule-based modeling}

To expand our model, we will need to expand our MCP molecule to include methylation of the MCP by CheR and demethylation of the MCP by CheB. We will use three methylation levels (low, medium, and high) rather than five because these three states are the most involved in the chemotaxis response to attractants.

Imagine that we were attempting to specify every reaction that could take place in our model. To specify an MCP, we would need to establish whether it is bound to a ligand (two possible states), whether it is bound to CheR (two possible states), whether it is phosphorylated (two possible states), and which methylation state it is in (three possible states). Therefore, a given MCP has $2 \cdot 2 \cdot 2 \cdot 3 = 24$ total states.

Consider the simple reaction of a ligand binding to an MCP, which we originally wrote as $T + L \rightarrow TL$. We now need this reaction to include 12 of the 24 states, the ones corresponding to the MCP being unbound to the ligand. Our previously simple reaction would become 12 different reactions, one for each possible unbound state of the complex molecule $T$. And if the situation were just a little more complex, with the ligand molecule $L$ having $n$ possible states, then we would have $12n$ reactions. Imagine trying to debug a model in which we had accidentally incorporated a typo when transcribing just one of these reactions!

In other words, as our model grows, with multiple different states for each molecule involved in each reaction, the number of reactions we need to represent the system grows rapidly; this phenomenon is called \textdef{combinatorial explosion}{combinatorial explosion}{a phenomenon in which the complexity of a problem grows rapidly due to the growth in the number of some quantity of interest (e.g., the number of possible reactions in a molecular system)} and means that building realistic models of biochemical systems at scale can be daunting.

Yet all of these 12 reactions can be summarized with a single \textit{rule}: a ligand and a receptor can bind into a complex if the receptor is unbound. This rule applies to all of the 12 states that an unbound receptor can have. Moreover, all 12 reactions implied by the rule are easily inferable from it. This idea is the foundation of \textdef{rule-based modeling}{rule-based modeling}{a paradigm in which a potentially enormous number of reactions are specified by a much smaller collection of ``rules'' from which all reactions can be inferred}, a paradigm in which a potentially enormous number of reactions are specified by a much smaller collection of ``rules'' from which all reactions can be inferred. 

We will not bog down the text with a full specification of all the rules needed to add methylation to our model. For the technical details required to build this expanded model of chemotaxis using rule-based modeling, please consult our tutorial online.\tutorial[chemotaxis/tutorial_adaptation]

%However, we will show the single rule representing ligand-receptor binding in the rule-based modeling language used by the BioNetGen software.\\

%\begin{BioNetGen}
%LigandReceptor: L(t) + T(l) <-> L(t!1).T(l!1) k_lr_bind, k_lr_dis
%\end{BioNetGen}

\FloatBarrier
\phantomsection
\subsection{Bacterial tumbling is robust to large sudden changes in attractant concentration}

In \autoref{fig:chemotaxis_tutorial_adaptation}, we plot the concentration over time of each molecule for different values of $l_0$, the initial concentration of ligand. From what we have learned about \textit{E. coli}, we should see the concentration of phosphorylated CheY (and therefore the bacterium's tumbling frequency) drop before returning to its original equilibrium. But will our simulation capture this behavior?

In \autoref{fig:chemotaxis_tutorial_adaptation} (first panel), we add a relatively small amount of attractant, setting $l_0$ equal to 100,000. The system returns so quickly to an equilibrium in phosphorylated CheY that it is difficult to imagine that the attractant has had any effect on tumbling frequency.

\begin{figure}[p]
\centering
\mySfFamily
\includegraphics[width = 0.8\textwidth]{../images/chemotaxis_tutorial_oneadd1e4.png}\\[2ex]
\includegraphics[width = 0.8\textwidth]{../images/chemotaxis_tutorial_oneadd1e6.png}\\[2ex]
\includegraphics[width = 0.8\textwidth]{../images/chemotaxis_tutorial_oneadd1e8.png}
\caption{Molecular concentrations over time (in seconds) in a chemotaxis simulation for a variety of initial attractant ligand particle numbers: 10,000 (first panel), 1,000,000 (second panel), and 100,000,000 (third panel). initial attractant ligand particles. Phosphorylated CheY, our metric for tumbling frequency, is shown in purple.}
\label{fig:chemotaxis_tutorial_adaptation}
\end{figure}

When we increase $l_0$ to 1 million, the initial drop is more pronounced, but the system returns  to equilibrium in a couple of minutes. Note how much higher the concentration of methylated receptors are in the second panel compared to the first panel of \autoref{fig:chemotaxis_tutorial_adaptation}; however, there are still a significant concentration of receptors with low methylation, indicating that the system may be able to handle an even larger jolt of attractant.

When we set $l_0$ equal to 100 million, we give the system this bigger jolt. Once again, the model returns to its previous CheY equilibrium after a few minutes, despite the steepest initial drop yet in the concentration of phosphorylated CheY (\autoref{fig:chemotaxis_tutorial_adaptation} (third panel)).

Our model, which is built on real reaction rate parameters, provides compelling evidence that the \textit{E. coli} chemotaxis system is robust to changes in its environment across several orders of magnitude of attractant concentration. This robustness has been observed in real bacteria and replicated by other computational simulations.

Aren't bacteria magnificent?

\phantomsection
\subsection{Traveling up an attractant gradient}

We have simulated \textit{E. coli} adapting to a single sudden change in its environment, but life often depends on responding to continual change. Imagine a glucose cube in an aqueous solution. As the cube dissolves, a \textdefnogloss{gradient} will form, with a glucose concentration that decreases outward from the cube. How will the tumbling frequency of \textit{E. coli} change if the bacterium finds itself in an environment of an attractant gradient?  Will the tumbling frequency decrease continuously as well, or will we see more complicated behavior? And once the cell reaches a region of high attractant concentration, will its default tumbling frequency stabilize to the same steady state?

We will modify our model by increasing the concentration of the attractant ligand at an exponential rate and seeing how the concentration of phosphorylated CheY changes. This model will simulate a bacterium traveling up an attractant gradient toward an attractant. Moreover, we will examine how the concentration of phosphorylated CheY changes as we change the gradient's ``steepness'', or the rate at which attractant ligand is increasing.\tutorial[chemotaxis/tutorial_gradient]

%\phantomsection
%\subsection{Steady state tumbling frequency is robust}

To model a ligand concentration $[L]$ that is increasing exponentially, we will use the function $[L] = l_0 \cdot e^{k \cdot t}$, where $k$ is a positive constant dictating the rate of exponential growth, $l_0$ is the initial concentration, and $t$ is the time. The parameter $k$ represents the steepness of the gradient, since the higher the value of $k$, the faster the growth in the ligand concentration $[L]$.

\autoref{fig:chemotaxis_tutorial_addition01} shows the concentration over time of phosphorylated CheY (shown in blue) when $l_0 = 1000$ and $k = 0.1$. The concentration of phosphorylated CheY, and therefore the tumbling frequency, still decreases sharply as the ligand concentration increases, but after all ligands become bound to receptors (shown by the plateau in the red curve), receptor methylation causes the concentration of phosphorylated CheY to return to its equilibrium. In other words, for these values of $l_0$ and $k$, the outcome is similar to when we provided an instantaneous increase in ligand, although the cell takes longer to reach its minimum concentration of phosphorylated CheY because the attractant concentration is increasing gradually.\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_tutorial_addition01.png}
\caption{Plots of molecular concentrations over time (in seconds) when the concentration of ligand grows exponentially with $\textvar{l}_\text{0} = \text{1000}$ and $\textvar{k} = \text{0.1}$. The concentration of bound ligand (red) quickly hits saturation, which causes a minimum in phosphorylated CheY (and therefore a low tumbling frequency). In response, the cell increases the methylation of receptors, which increases the concentration of phosphorylated CheY (purple) back to equilibrium.}
\label{fig:chemotaxis_tutorial_addition01}
\end{figure}

\autoref{fig:chemotaxis_tutorial_addition03} shows the results of multiple simulations in which we vary the growth parameter $k$ and plot only the concentration of phosphorylated CheY over time. The larger the value of $k$, the faster the increase in receptor binding, and the steeper the drop in the concentration of phosphorylated CheY.

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.8\textwidth]{../images/chemotaxis_tutorial_addition03.png}
\caption{Plots of the concentration of phosphorylated CheY over time (in seconds) for different growth rates \textvar{k} of ligand concentration. The larger the value of \textvar{k}, the steeper the initial drop in the concentration of phosphorylated CheY, and the faster that methylation returns the concentration of phosphorylated CheY to equilibrium. The same equilibrium is obtained regardless of the value of \textvar{k}.}
\label{fig:chemotaxis_tutorial_addition03}
\end{figure}

More importantly, \autoref{fig:chemotaxis_tutorial_addition03} further illustrates the \textit{robustness} of bacterial chemotaxis to the rate of growth in ligand concentration. Whether the growth of the attractant is slow or fast, methylation will always bring the cell back to the same equilibrium concentration of phosphorylated CheY and therefore the same background tumbling frequency.\\

\begin{qbox}[%
We can simulate a bacterium traveling \textit{down} an attractant gradient if $k$, the parameter representing the steepness of the gradient, is negative. In this case, what do you think that the plot of the concentration of phosphorylated CheY over time will look like?
]\end{qbox}

\FloatBarrier
\phantomsection
\subsection{From changing tumbling frequencies to an exploration algorithm}

We hope that our work in this chapter has conveyed the elegance of bacterial chemotaxis, as well as the power of rule-based modeling and the Gillespie algorithm for simulating a complex biochemical system that may include a huge number of reactions.

And yet we are missing an important part of the story. \textit{E. coli} has evolved to ensure that if it detects a relative increase in concentration (i.e., an attractant gradient), then it can reduce its tumbling frequency in response. But we have not explored \textit{why} changing its tumbling frequency would help a bacterium find food in the first place. After all, according to the run and tumble model, the direction that a bacterium is moving at any point in time is random!

This quandary does not have an obvious intuitive answer. In this chapter's conclusion, we will build a model to explain why \textit{E. coli}'s randomized run and tumble walk algorithm is such a clever way of locating resources in an unfamiliar land.\\


\FloatBarrier
\phantomsection

\section{Conclusion: The Beauty of \textit{E. coli}'s Robust Randomized Exploration Algorithm}
\label{sec:conclusion}

\phantomsection
\subsection{Two randomized exploration strategies}

In \autoref{chapter:turing}, we saw that a particle taking a collection of \textit{n} unit steps in random directions will wind up on average a distance proportional to $\sqrt{n}$ units away from its starting position. We would like to compare such a random walk against a modified random walk that emulates the behavior of \textit{E. coli} by changing the length of a step based on the relative change in background attractant concentration.

We will represent a bacterium as a particle traveling in two-dimensional space. Units of distance will be measured in µm; recall from the introduction that a bacterium can cover 20 µm in a second during an uninterrupted run. The bacterium will start at the \textbf{origin} $(0, 0)$.

We will use $L(x,y)$ to denote the ligand concentration at $(x, y)$ and establish a point (called the \textbf{goal}) at which $L(x,y)$ is maximized. We will place the goal at $(\text{1,500}, \text{1,500})$, so that the bacterium must travel a significant distance from the origin to reach the goal.

We would like the ligand concentration $L(x,y)$ to decrease exponentially the farther we travel from the goal. We therefore set $L(x,y) = 100 \cdot 10^{6 \cdot (1-d/D)}$, where $d$ is the distance from $(x, y)$ to the goal, and $D$ is the distance from the origin to the goal, which in this case is $\text{1,500}\sqrt{2} \approx 2121$ µm. At the origin, the attractant concentration is equal to 100, and at the goal, the attractant concentration is equal to 100,000,000.  \\

\begin{qbox}[%
How can we quantify how well a bacterium has done at finding the attractant?
]\end{qbox}

We are comparing two different cellular behaviors, and so in the spirit of \autoref{chapter:motifs}, we will simulate many random walks of a particle following each of the two strategies, described in what follows. (The total time needed by our simulation should be large enough to allow the bacterium to have enough time to reach the goal.) For each strategy, we will then measure how far \textit{on average} a bacterium with each strategy is from the goal at the end of the simulation.

\FloatBarrier
\phantomsection
\subsection{Strategy 1: Standard random walk}

To model a particle following an ``unintelligent'' random walk strategy, we first select a random direction of movement along with a duration of tumble. The angle of reorientation is a random number selected uniformly between 0° and 360°. The duration of each tumble is a ``wait time'' of sorts and follows an exponential distribution with experimentally verified mean equal to 0.1 seconds.

We then select a random duration to run and let the bacterium run in that direction for the specified amount of time.  The duration of each run follows an exponential distribution with mean equal to the experimentally verified value of 1 second.

We then iterate the two steps of tumbling and running until the total time allocated for the simulation has elapsed.\tutorial[chemotaxis/tutorial_purerandom]

\FloatBarrier
\phantomsection
\subsection{Strategy 2: Chemotactic random walk}

In our second strategy, we mimic the real response of \textit{E. coli} to its environment based on what we have learned about chemotaxis throughout this chapter. The simulated bacterium will still follow a run and tumble model, but the duration of each run, which is a function of its tumbling frequency, will depend on the relative change in attractant concentration that it detects.

To ensure a mathematically controlled comparison, we will use the same approach for sampling the duration of a tumble and the direction of a run as in the first strategy.

We have seen, going back to \autoref{fig:chemotaxis_concentrations}, that it takes \textit{E. coli} about half a second to respond to a change in attractant concentration. We use $t_{\text{response}}$ to denote this ``response time''; to produce a reasonable model of chemotaxis, we will check the attractant concentration of a running particle at the particle's current location every $t_{\text{response}}$ seconds.

We will then measure the percentage difference between the attractant concentration $L(x,y)$ at the cell's current point and the attractant concentration at the cell's previous point, $t_{\text{response}}$ seconds in the past; we denote this difference as $\Delta[L]$. If $\Delta[L]$ is equal to zero, then the probability of a tumble in the next $t_{\text{response}}$ seconds should be the same as the likelihood of a tumble in the first strategy over the same time period. If $\Delta[L]$ is positive, then the probability of a tumble should be greater than it was in strategy 1; if $\Delta[L]$ is negative, then the probability of a tumble should be less than it was in strategy 1.

To model the relationship between the likelihood of a tumble and the value of $\Delta[L]$, we will let $t_0$ denote the mean background run duration, which in the first strategy was equal to one second. We would like to use a simple formula for the expected run duration like $t_0 \cdot (1 + 10 \cdot \Delta[L])$.

Unfortunately, there are two issues with this formula. First, if $\Delta[L]$ is less than -0.1, then the run duration could be negative. Second, if $\Delta[L]$ is large, then the bacterium will run for so long that it could reach the goal and run past it.

To fix the first issue, we will first take the maximum of $t_0 \cdot (1 + 10 \cdot \Delta [L])$ and some small positive number $c$ (we will use $c$ equal to 0.000001). As for the second issue, we will then take the minimum of this expression and $4 \cdot t_0$. This resulting value,

\begin{center}
$\min\left(\max(t_0 \cdot (1 + 10 \cdot \Delta [L]), c), 4 \cdot t_0\right)$\,,
\end{center}

\noindent becomes the mean run duration of a bacterium based on the recent relative change in concentration.\\

\begin{qbox}[%
What is the mean run duration when $\Delta\text{[}L\text{]}$ is equal to zero? Is this what we would hope?
]\end{qbox}

As with the first strategy, our simulated cell will alternate between tumbling and running in a random direction until the total time devoted to the simulation has elapsed. The \textit{only} difference in the second strategy is that we will measure the percentage change in concentration $\Delta [L]$ between a cell's current point and its previous point every $t_{\text{response}}$ seconds. After determining a mean run time according to the expression above, we will sample a random number $p$ from an exponential distribution with this mean run time, and the cell will tumble after $p$ seconds if $p$ is smaller than $t_{\text{response}}$.\tutorial[chemotaxis/tutorial_gradient]

\FloatBarrier
\phantomsection
\subsection{Comparing the effectiveness of our two random walk strategies}

\autoref{fig:chemotaxis_traj_compare_uniform} visualizes the trajectories of three cells over 500 seconds using strategy 1 (left) and strategy 2 (right) with a default tumbling frequency $t_0$ of one second. Unlike the cells following strategy 1, the cells following strategy 2 quickly hone in on the goal and remain near it.\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.85\textwidth]{../images/chemotaxis_traj_compare_uniform.png}
\caption{Three sample trajectories for the standard random walk strategy (left) and chemotactic random walk strategy (right) with a default tumbling frequency of one second. Redder regions correspond to higher concentrations of ligand, with a goal having maximum concentration at the point $(\text{1,500}, \text{1,500})$, which is indicated with a blue square. Each particle's walk is colored from darker to lighter colors across the time frame of its trajectory.}
\label{fig:chemotaxis_traj_compare_uniform}
\end{figure}

Of course, we should be wary of such a small sample size. To confirm that what we observed in these trajectories is true in general, we will compare the two strategies over many simulations. \autoref{fig:chemotaxis_performance_compare_uniform} visualizes the particle's average distance to the goal over 500 simulations for both strategies and confirms our previous observation that strategy 2 is effective at guiding the simulated particle to the goal. And yet this strategy is driven by \textit{random} choices of direction of travel, so why would it be so successful?\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.8\textwidth]{../images/chemotaxis_performance_compare_uniform.png}
\caption{Distance to the goal plotted over time for 500 simulated particles following the standard random walk (pink) and the chemotactic random walk (green). The dark lines indicate the average distance over all simulations, and the shaded area around each line represents one standard deviation from the average.}
\label{fig:chemotaxis_performance_compare_uniform}
\end{figure}

The chemotactic strategy works because it uses a ``rubber band'' effect. If the bacterium is traveling down an attractant gradient (i.e., away from an attractant), then it is not allowed to travel very far in a single step before it is forced to tumble. If an increase of attractant is detected, however, then the cell can travel farther in a single direction before tumbling. On average, this effect serves to pull the bacterium in the direction of increasing attractant, even though the directions in which it travels are random.

A tiny change to a simple, unsuccessful randomized algorithm can therefore produce an elegant approach for exploring an unknown environment. But we left one more question unanswered: why is a default frequency of one tumble per second stable across a wide range of bacteria? To address this question, we will see how changing $t_0$, the default time for a run step in the absence of change in attractant concentration, affects the ability of a simulated bacterium following strategy 2 to reach the goal.\tutorial[chemotaxis/tutorial_tumbling_frequencies]

\FloatBarrier
\phantomsection
\subsection{Why is background tumbling frequency constant across bacterial species?}

\autoref{fig:chemotaxis_traj_low_high_tumbling} shows three trajectories for two different values of $t_0$ in a simulation that lasts for 800 seconds. When $t_0$ is equal to 0.2 seconds, the simulated bacteria are not able to walk far enough in a single step to head toward the goal (\autoref{fig:chemotaxis_traj_low_high_tumbling} (left)). If we increase $t_0$ to 5.0 seconds, then the particles run for so long that they may run past the goal without being able to apply the brakes by tumbling (\autoref{fig:chemotaxis_traj_low_high_tumbling} (right)). When we set $t_0$ equal to 1.0, we obtain the trajectories from \autoref{fig:chemotaxis_traj_compare_uniform} (right), exhibiting a ``Goldilocks'' effect in which the simulated bacterium can run for long enough at a time to head quickly toward the goal, and it tumbles frequently enough to keep it there.\\

\begin{figure}[h]
\centering
\mySfFamily
\tabcolsep = 0.5em
\begin{tabular}{c c}
\includegraphics[width = 0.4\textwidth]{../images/chemotaxis_traj_0.2_uniform.png} & \includegraphics[width = 0.4\textwidth]{../images/chemotaxis_traj_5.0_uniform.png}
\end{tabular}
\caption{Three sample trajectories of a simulated cell following the chemotactic random walk strategy with an average run time between tumbles $\textvar{t}_\text{0}$ of 0.2 seconds (left) and 5.0 seconds (right).}
\label{fig:chemotaxis_traj_low_high_tumbling}
\end{figure}

\autoref{fig:chemotaxis_performance_uniform} visualizes average particle distance to the goal over time for 500 particles using a variety of choices of $t_0$. It confirms that tumbling every second by default is ``just right'' for finding an attractant.\\

\begin{figure}[h]
\centering
\mySfFamily
\includegraphics[width = 0.8\textwidth]{../images/chemotaxis_performance_uniform.png}
\caption{Distance to the goal plotted over time for 500 simulated particles using a variety of different values of $\textvar{t}_\text{0}$. As in \autoref{fig:chemotaxis_performance_compare_uniform}, dark lines indicate the average distance over all simulations, and the shaded area around each line represents one standard deviation from the average.}
\label{fig:chemotaxis_performance_uniform}
\end{figure}

\phantomsection
\subsection{Bacteria are even smarter than we thought}

When we watch bacteria reorient under a microscope, their behavior appears more intelligent than choosing random directions of travel. As is often true in biology, the reality of the system that we are studying turns out to be more complex than we might at first imagine.

The direction of bacterial reorientation is not completely random, but rather follows a normal distribution with mean of 68° and standard deviation of 36°. That is, the bacterium typically does not tend to make as drastic of a change to its orientation as it would in a pure random walk, which would on average have a change in orientation of 90°.

Furthermore, the direction of the bacterium's reorientation also depends on whether the cell is traveling in the correct direction. If the bacterium is moving up an attractant gradient, then it makes smaller changes in its reorientation angle, a feature that helps the cell continue moving straight if it is traveling in the direction of an attractant.

We are fortunate to have this wealth of research on chemotaxis in \textit{E.~coli}, which may be the single most studied biological system from the perspective of demonstrating how chemical reactions produce emergent behavior. However, for the study of most biological systems, finding a clear thread connecting a reductionist view of the system to that system's holistic behavior remains a dream. (For example: how can your thoughts while reading this parenthetical aside be distilled into the firings of individual neurons?)  Regardless of what the future holds, we can be confident that uncovering the underlying mechanisms of biological systems will continue to inspire the work of biological modelers for many years.\\

\newpage

\FloatBarrier
\phantomsection
\section{Exercises}

\subsection{How does \textit{E.~coli} respond to repellents?}

Just as \textit{E.~coli} has receptors that bind to attractant ligands, it has other receptors that can bind to \textdefnogloss{repellent} ligands. Attractant-ligand binding causes an increase in the autophosphorylation of CheA, but repellent-ligand binding causes a decrease in the autophosphorylation of CheA.\\

\begin{exercise}[%
Based on what we have learned in this module about how \textit{E.~coli} and other bacteria act in the presence of an attractant, what do you think that the chemotaxis response is in the presence of a repellent? How do you think that the bacterium adjusts to relative changes of the repellent?
]\end{exercise}

We learned that \textit{E.~coli} is likely to run for longer when traveling up an attractant gradient because of an decrease in phosphorylated CheY, causing less tumbling. As a result, the bacterium can find attractant sources despite running in randomly chosen directions. For the same reason, \textit{E.~coli} is likely to run for longer when traveling \textit{down} a repellent gradient.\\

\begin{exercise}[%
Adapt the ``chemotactic'' random walk strategy to handle the fact that bacteria sensing a relative decrease in repellent concentration will have longer runs before tumbling. Simulate this strategy for a collection of particles placed near a ``goal'' representing a repellent source. What is the average distance of the particles from the goal? How does this compare to the average distance to the goal for a collection of particles following a pure random walk? And how does the distance to the goal change as we change $t_0$, the default time between tumbles?
]\end{exercise}

\subsection{Traveling down an attractant gradient}

A related question to how a bacterium responds to a repellent is how it responds to traveling \textit{away} from an attractant, i.e., down an attractant gradient. To model this situation, we will still use the function $[L] = l_0 \cdot e^{k \cdot t}$ that we used when modeling a bacterium traveling up an attractant gradient, but we will now assume that $k$ is negative so that the concentration is decaying exponentially. Refer to that tutorial for details.\tutorial[tutorial_walk]\\

\begin{exercise}[%
Adapt the simulation that we used to produce \autoref{fig:chemotaxis_tutorial_addition01} to model the concentration of phosphorylated CheY over time for an exponentially decaying attractant concentration. How does the plot of phosphorylated CheY change as $k$ gets more negative?
]\end{exercise}

\subsection{What if \textit{E.~coli} has multiple attractant sources?}

Not only can \textit{E.~coli} sense both repellents and attractants, but it can detect \textit{more than one} attractant gradient at the same time.  This function has a clear evolutionary purpose in a bacterial environment of multiple sparsely populated food sources. In this section, we will explore whether the chemotaxis mechanism allows cells to navigate through heterogeneous nutrient distributions.\\

\begin{exercise}[%
Modify our Gillespie model of chemotaxis adaptation to reflect two types of receptor, each specific to its own ligand (call them \textvar{A} and \textvar{B}). Assume that we have 3500 receptor molecules of each type.
]\end{exercise}

In the previous exercise, the cell adapts to the presence of two different attractants at the same time. We now consider what will happen if we only add \textvar{B} molecules once the cell has already adapted to \textvar{A} molecules.\\

\begin{exercise}[%
Change your model from the previous exercise by assuming that after the cell adapts to 1,000,000 molecules of \textvar{A}, 1,000,000 molecules of \textvar{B} are added. Observe the concentration of phosphorylated CheY. Is the cell able to respond to \textvar{B} after adapting to the concentration of ligand \textvar{A}? Why do you think that the change in CheY phosphorylation different from the scenario in which we release the two different ligands concurrently?
]\end{exercise}

When modeling a chemotactic random walk, we used a concentration gradient that grew exponentially toward a single goal. Specifically, if $L(x,y)$ was the concentration of ligand at $(x, y)$, we set $L(x,y) = 100 \cdot 10^{6 \cdot (1-d/D)}$, where $d$ is the distance from $(x,y)$ to the goal, and $D$ is the distance from the origin to the goal (we used a goal of $(\text{1,500}, \text{1,500})$).

To generalize this simulation to an environment with more than one attractant source, we will include another goal at $(-\text{1,500}, \text{1,500})$. The new ligand concentration formula will be $L(x, y) = 100 \cdot 10^{6 \cdot (1-d_1/D_1)} + 100 \cdot 10^{6 \cdot (1-d_2/D_2)}$, where $d_1$ is the distance from $(x, y)$ to the goal at $(\text{1,500}, \text{1,500})$, $d_2$ is the distance from $(x, y)$ to the goal at $(-\text{1,500}, \text{1,500})$, and $D_1$ and $D_2$ are the distances from the origin to the two respective goals.\\

\begin{exercise}[%
Change the chemotactic walk simulation so that it includes the two goals, and visualize the trajectories of several particles using a background tumbling frequency of once every second. Are the particles able to find one of the goals? How long does it take them, and how does this compare against the case of a single goal?
]\end{exercise}

\begin{exercise}[%
Vary the tumbling frequency according to the parameters given in the chemotactic walk tutorial to see how tumbling frequency influences the average distance of a cell to the closer of the two goals. As in the tutorial, run your simulation for 500 particles with the default time between tumbles ($t_0$) equal to each of 0.2, 0.5, 1.0, 2.0 and 5.0 seconds.
]\end{exercise}

\subsection{Changing the \textit{E.~coli} choice of direction}

In the conclusion, we mentioned that when \textit{E.~coli} tumbles, the degree of reorientation is not uniformly random from 0° to 360°. Rather, research has shown that it follows a normal distribution with mean of 68° (1.19 radians) and standard deviation of 36° (0.63 radians).\\

\begin{exercise}[%
Modify your model from the chemotactic walk tutorial to change the random uniform sampling to this ``smarter'' sampling. Compare the chemotactic walk strategy and this smarter strategy by calculating the mean and standard deviation of each cell's distance to the goal for 500 simulated cells with the default running time $t_0$ equal to each of 0.2, 0.5, 1.0, 2.0 and 5.0 seconds. Do these simulated cells do a better job of finding the goal?
]\end{exercise}

More recent research suggests that when the bacterium is moving up an attractant gradient, the degree of reorientation may be even smaller. The question is whether reducing the reorientation angle improves a cell's chemotaxis response.\\

\begin{exercise}[%
Modify your model from the previous exercise so that if the cell has just made a move of increasing ligand concentration, then its mean reorientation angle is 0.1 radians smaller to change the random uniform sampling to this "smarter" sampling. Calculate  the mean and standard deviation of each cell's distance to the goal for 500 cells with the default running time $t_0$ equal to each of 0.2, 0.5, 1.0, 2.0 and 5.0 seconds. Do the cells find the goal faster?
]\end{exercise}

\subsection{Can't get enough rule-based modeling?}

As we have seen in this chapter, rule-based modeling is successful at simulating systems that involve a large number of species and particles but can be summarized with a small set of rules.

\textdefnogloss{Polymerization} reactions offer another good example of such a system. Polymerization is the process by which \textdefnogloss{monomer} molecules combine into chains called \textdefnogloss{polymers}. Biological polymers are everywhere, from DNA (formed of monomer nucleotides) to proteins (formed of monomer amino acids) to lipids (formed of monomer fatty acids). For a nonbiological example, polyvinyl chloride (which lends its name to ``PVC pipe'') is a polymer made up of many vinyl molymers.

We would like to simulate the polymerization of copies of a monomer \textvar{A} to form a polymer \textvar{AAAAAA}\ldots, where the length of the polymer is allowed to vary. If we simulate this process, we are curious what the distribution of the polymer lengths will be.

We will write our polymer reaction as

\begin{center}
$A_m + A_n \rightarrow A_{m+n}$\,,
\end{center}

\noindent where $A_m$ denotes a polymer consisting of \textvar{m} copies of \textvar{A}. Using classical reaction rules, this would require an infinite number of reactions; will rule-based modeling come to our rescue?

There are two sites on the monomer \textvar{A} that are involved in a polymerization reaction: the ``head'' and the ``tail''. A polymer $A_m$ containing $m$ monomers can be viewed as the result of $m-1$ binding reactions of the head of one monomer and the tail of another. As a result, the infinitely many polymer reactions can be summarized with the single rule ``If one monomer has an unbound head and another has an unbound tail, then the two monomers can bind.''

Unfortunately, even though these reactions can be summarized with a single rule, the number of possible reactions is infinite! As a result, we cannot apply the Gillespie algorithm and will need to apply an alternative called ``network-free simulation'', which avoids having to generate all possible reactions. We appeal to the \textit{Biological Modeling} website version of this section for a complete specification of how to build this polymer simulation.\tutorial[chemotaxis/exercises]\\

\begin{exercise}[%
Run the simulation. How do the concentrations of polymers vary according to the lengths of the polymers?
]\end{exercise}

\begin{exercise}[%
What happens to polymer concentrations as we change the polymer binding and dissociation rates? Does your observation reflect what you might expect?
]\end{exercise}

%\subsection{A method for generating random numbers from exponential distribution}


%\FloatBarrier
%\phantomsection
%\section{Citations}
%\citep{Munroe_2014}
%\citep{Pierucci_1978}
%\citep{Sim_2017}
%\citep{Baker_2005}
%\citep{Yong_2016}
%\citep{Weis_1990, Berg_2000}
%\citep{Achouri_2015, Turner_2016, Gotz_1987}
%\citep{Li_2004, Spiro_1997, Stock_1991}
%\citep{Schwartz_2008}
% \citep{Amin_2010, Terwilliger_1986}
% \citep{Spiro_1997}
% \citep{Spiro_1997}
% \citep{Lupas_1989}
%\citep{Boyd_1980}
%\citep{Shimizu_2005, Krembel_2015}
%\citep{Bray_1993}
%\citep{Krembel_2015}.
%\citep{Saragosti_2012}
